{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython2",
  "version": 2,
  "kernelspec": {
   "name": "python37564bittf2venvc8b629ebe0524d9f9a8acaa915081f11",
   "display_name": "Python 3.7.5 64-bit ('tf2': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import model.cell as cell\n",
    "import model.spec as spec\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(50000, 32, 32, 3)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0 1 0 0 0 1]\n [0 0 1 0 0 0]\n [0 0 0 1 0 1]\n [0 0 0 0 1 0]\n [0 0 0 0 0 1]\n [0 0 0 0 0 0]]\n['input', 'conv1x1-bn-relu', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'conv3x3-bn-relu', 'output']\n"
    },
    {
     "data": {
      "text/plain": "[128, 64, 64, 64, 64, 128]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cf = spec.Spec.get_configuration_space().sample_configuration()\n",
    "s = spec.Spec(cf)\n",
    "while s.valid_spec == False:\n",
    "    cf = spec.Spec.get_configuration_space().sample_configuration()\n",
    "    s = spec.Spec(cf)\n",
    "\n",
    "c = cell.Cell(s, 64)\n",
    "\n",
    "print(s.matrix)\n",
    "print(s.ops)\n",
    "c.compute_vertex_channels(128, 128, s.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sample_cell\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_17 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n__________________________________________________________________________________________________\nconv2d_56 (Conv2D)              (None, 32, 32, 32)   96          input_17[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_56 (BatchNo (None, 32, 32, 32)   128         conv2d_56[0][0]                  \n__________________________________________________________________________________________________\nre_lu_56 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_56[0][0]     \n__________________________________________________________________________________________________\nconv2d_57 (Conv2D)              (None, 32, 32, 32)   1024        re_lu_56[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_57 (BatchNo (None, 32, 32, 32)   128         conv2d_57[0][0]                  \n__________________________________________________________________________________________________\nre_lu_57 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_57[0][0]     \n__________________________________________________________________________________________________\nconv2d_58 (Conv2D)              (None, 32, 32, 32)   9216        re_lu_57[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_58 (BatchNo (None, 32, 32, 32)   128         conv2d_58[0][0]                  \n__________________________________________________________________________________________________\nre_lu_58 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_58[0][0]     \n__________________________________________________________________________________________________\nconv2d_59 (Conv2D)              (None, 32, 32, 32)   9216        re_lu_58[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_59 (BatchNo (None, 32, 32, 32)   128         conv2d_59[0][0]                  \n__________________________________________________________________________________________________\nre_lu_59 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_59[0][0]     \n__________________________________________________________________________________________________\nconv2d_60 (Conv2D)              (None, 32, 32, 32)   9216        re_lu_59[0][0]                   \n__________________________________________________________________________________________________\nbatch_normalization_60 (BatchNo (None, 32, 32, 32)   128         conv2d_60[0][0]                  \n__________________________________________________________________________________________________\nre_lu_60 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_60[0][0]     \n__________________________________________________________________________________________________\nconcatenate_8 (Concatenate)     (None, 32, 32, 64)   0           re_lu_58[0][0]                   \n                                                                 re_lu_60[0][0]                   \n__________________________________________________________________________________________________\nflatten_2 (Flatten)             (None, 65536)        0           concatenate_8[0][0]              \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 64)           4194368     flatten_2[0][0]                  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 10)           650         dense_4[0][0]                    \n==================================================================================================\nTotal params: 4,224,426\nTrainable params: 4,224,106\nNon-trainable params: 320\n__________________________________________________________________________________________________\ninput_17 [(None, 32, 32, 3)]\nconv2d_56 (None, 32, 32, 32)\nbatch_normalization_56 (None, 32, 32, 32)\nre_lu_56 (None, 32, 32, 32)\nconv2d_57 (None, 32, 32, 32)\nbatch_normalization_57 (None, 32, 32, 32)\nre_lu_57 (None, 32, 32, 32)\nconv2d_58 (None, 32, 32, 32)\nbatch_normalization_58 (None, 32, 32, 32)\nre_lu_58 (None, 32, 32, 32)\nconv2d_59 (None, 32, 32, 32)\nbatch_normalization_59 (None, 32, 32, 32)\nre_lu_59 (None, 32, 32, 32)\nconv2d_60 (None, 32, 32, 32)\nbatch_normalization_60 (None, 32, 32, 32)\nre_lu_60 (None, 32, 32, 32)\nconcatenate_8 (None, 32, 32, 64)\nflatten_2 (None, 65536)\ndense_4 (None, 64)\ndense_5 (None, 10)\n"
    }
   ],
   "source": [
    "i = tf.keras.Input(shape=(32, 32, 3))\n",
    "o = c.build(i)\n",
    "o = tf.keras.layers.Flatten()(o)\n",
    "o = tf.keras.layers.Dense(64, activation='relu')(o)\n",
    "o = tf.keras.layers.Dense(10)(o)\n",
    "\n",
    "model = tf.keras.Model(i, o, name=\"sample_cell\")\n",
    "model.summary()\n",
    "\n",
    "for l in model.layers:\n",
    "    print(\"%s %s\" % (l.name, str(l.output_shape)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train on 50000 samples, validate on 10000 samples\nEpoch 1/5\n50000/50000 [==============================] - 10s 200us/sample - loss: 2.3707 - accuracy: 0.1042 - val_loss: 2.3027 - val_accuracy: 0.1000\nEpoch 2/5\n50000/50000 [==============================] - 9s 189us/sample - loss: 2.3031 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 3/5\n50000/50000 [==============================] - 9s 188us/sample - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 4/5\n50000/50000 [==============================] - 9s 187us/sample - loss: 2.3028 - accuracy: 0.0961 - val_loss: 2.3026 - val_accuracy: 0.1000\nEpoch 5/5\n50000/50000 [==============================] - 9s 188us/sample - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=5, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}